{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 2024\n",
    "# Model training - XLM-RoBERTa using pytorch\n",
    "# Violeta Berdejo-Espinola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2152907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /Users/uqvberde/Projects/classifier_spanish/venv/.venv/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/uqvberde/Projects/classifier_spanish/venv/.venv/lib/python3.11/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/uqvberde/Projects/classifier_spanish/venv/.venv/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Using cached tokenizers-0.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/uqvberde/Projects/classifier_spanish/venv/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/uqvberde/Projects/classifier_spanish/venv/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "Using cached huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "Using cached tokenizers-0.20.1-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 huggingface-hub-0.26.1 idna-3.10 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.1 tqdm-4.66.5 transformers-4.45.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8000d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "mps\n",
      "('14.7', ('', '', ''), 'arm64')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mpu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(torch.backends.mps.is_built()) # checking if mps is available \n",
    "device = torch.device('mps')\n",
    "print(device)\n",
    "\n",
    "import platform; \n",
    "print(platform.mac_ver()) # checking pytorch version for mac - should be arm54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d1fc0",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61517bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mpu.io.read('../data/X_train_xlm.pickle').to(device)\n",
    "X_test = mpu.io.read('../data/X_test_xlm.pickle').to(device)\n",
    "y_train = mpu.io.read('../data/y_train_xlm.pickle').to(device)\n",
    "y_test = mpu.io.read('../data/y_test_xlm.pickle').to(device)\n",
    "\n",
    "class_weights = mpu.io.read('../data/class_weights.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3cc19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     0, 107950,  43269,  ...,      1,      1,      1],\n",
       "        [     0,  45709,   4503,  ...,      1,      1,      1],\n",
       "        [     0,    527,   7695,  ...,      1,      1,      1],\n",
       "        ...,\n",
       "        [     0,  10934,    318,  ...,      1,      1,      1],\n",
       "        [     0, 177652,     31,  ...,   1124, 205292,      2],\n",
       "        [     0,  84790,  49835,  ...,      1,      1,      1]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='mps:0')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ad4a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_ros' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# X_train_ros = mpu.io.read('../data/embedding_train_ros.pickle')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# X_test_ros = mpu.io.read('../data/embedding_test_ros.pickle')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# y_train_ros = mpu.io.read('../data/y_train_emb_ros.pickle')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# y_test_ros = mpu.io.read('../data/y_test_emb_ros.pickle')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m X_train_ros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mX_train_ros\u001b[49m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m X_test_ros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test_ros)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m y_train_ros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train_ros)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_ros' is not defined"
     ]
    }
   ],
   "source": [
    "# X_train_ros = mpu.io.read('../data/embedding_train_ros.pickle')\n",
    "# X_test_ros = mpu.io.read('../data/embedding_test_ros.pickle')\n",
    "# y_train_ros = mpu.io.read('../data/y_train_emb_ros.pickle')\n",
    "# y_test_ros = mpu.io.read('../data/y_test_emb_ros.pickle')\n",
    "\n",
    "X_train_ros = torch.from_numpy(X_train_ros).to(device)\n",
    "X_test_ros = torch.from_numpy(X_test_ros).to(device)\n",
    "y_train_ros = torch.tensor(y_train_ros).to(device)\n",
    "y_test_ros = torch.tensor(y_test_ros).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4fc7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3966,   49], device='mps:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train['input_ids'])\n",
    "y_train.bincount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6182f27",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c0564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (XLMRobertaForSequenceClassification, AutoTokenizer)\n",
    "\n",
    "id2label = {'negative': 0, \n",
    "            'positive': 1}\n",
    "label2id = {0: 'negative',\n",
    "            1: 'positive'}\n",
    "\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base',\n",
    "                                                            num_labels=2, \n",
    "                                                            id2label=id2label, \n",
    "                                                            label2id=label2id).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# freeze transformer model parametres\n",
    "\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da856ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloaders\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# TensorDataset(input_features, labels)\n",
    "\n",
    "train_xlm = TensorDataset(X_train['input_ids'], X_train['attention_mask'], y_train)\n",
    "train_sampler = RandomSampler(train_xlm)\n",
    "train_dataloader = DataLoader(train_xlm, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_xlm = TensorDataset(X_test['input_ids'], X_test['attention_mask'], y_test)\n",
    "test_dataloader = DataLoader(test_xlm, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "649b752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch:  1 forward and backward pass of ALL training examples\n",
    "# bacth size: number of training samples in one forward and backwards pass\n",
    "# number of iterations: number of passes until the model has seen ALL examples. Each pass using batch_size number of samples\n",
    "# if 100 samples, batch_size=20, then it does 5 iterations per epoch to see ALL examples\n",
    "\n",
    "# if learning rate is too small:\n",
    "# - model goes through many iteartions to converge\n",
    "# - the loss does not change\n",
    "\n",
    "# defining parametres for gardient descent\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# loss function and optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1) # try 0.1\n",
    "\n",
    "# total number of training steps is number of batches * number of epochs\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# create the learning rate scheduler\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375304cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "\n",
    "def Trainer(model, dataloader, epochs, batch_size, device, optimizer, scheduler):\n",
    "    # Store the average loss after each epoch \n",
    "    loss_values = []\n",
    "\n",
    "    # number of total steps/iterations for each epoch\n",
    "    print('total steps per epoch: ', len(dataloader) // batch_size)\n",
    "\n",
    "    # looping over epochs\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print('training on epoch: ', epoch_i)\n",
    "\n",
    "        # set start time \n",
    "        t0 = time.time()\n",
    "        # reset total loss\n",
    "        total_loss = 0\n",
    "\n",
    "        # model in training \n",
    "        model.train()\n",
    "\n",
    "        # loop through batch \n",
    "        for step, batch in enumerate(dataloader):\n",
    "\n",
    "            # Progress update every 50 step \n",
    "            if step % 50 == 0 and not step == 0:\n",
    "                print('training on step: ', step)\n",
    "                print('total time used is: {0:.2f} s'.format(time.time() - t0))\n",
    "\n",
    "            # load data from dataloader \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            # clear any previously calculated gradients \n",
    "            model.zero_grad()\n",
    "\n",
    "            # get outputs\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "            \n",
    "            # get loss\n",
    "            loss = outputs[0]\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # update optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # update learning rate \n",
    "            scheduler.step()\n",
    "\n",
    "            # total loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # clip the norm of the gradients to 1.0.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)         \n",
    "\n",
    "        # Calculate the average loss over the training data.\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Store the loss value for plotting the learning curve.\n",
    "        loss_values.append(avg_train_loss)\n",
    "        \n",
    "        print(\"average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3085bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps per epoch:  0\n",
      "training on epoch:  0\n",
      "average training loss: 4.2812\n",
      "training on epoch:  1\n",
      "average training loss: 3.7304\n",
      "training on epoch:  2\n",
      "average training loss: 1.9712\n",
      "training on epoch:  3\n",
      "average training loss: 1.6155\n",
      "training on epoch:  4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m results5  \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36mTrainer\u001b[0;34m(model, dataloader, epochs, batch_size, device, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# get outputs\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# get loss\u001b[39;00m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1208\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1208\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1220\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    828\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    830\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    831\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    832\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    850\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    514\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    515\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:456\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    453\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    454\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 456\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:469\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    468\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 469\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:381\u001b[0m, in \u001b[0;36mXLMRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    380\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 381\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "import time\n",
    "results5  = Trainer(model, train_dataloader, epochs, batch_size, device, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ddc3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps per epoch:  0\n",
      "training on epoch:  0\n",
      "average training loss: 2.3174\n",
      "training on epoch:  1\n",
      "average training loss: 1.4516\n",
      "training on epoch:  2\n",
      "average training loss: 2.5991\n",
      "training on epoch:  3\n",
      "average training loss: 2.4311\n",
      "training on epoch:  4\n",
      "average training loss: 9.6161\n",
      "training on epoch:  5\n",
      "average training loss: 7.4811\n",
      "training on epoch:  6\n",
      "average training loss: 2.7938\n",
      "training on epoch:  7\n",
      "average training loss: 1.4248\n",
      "training on epoch:  8\n",
      "average training loss: 3.4504\n",
      "training on epoch:  9\n",
      "average training loss: 1.7083\n",
      "training on epoch:  10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m results5  \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36mTrainer\u001b[0;34m(model, dataloader, epochs, batch_size, device, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# get outputs\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# get loss\u001b[39;00m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1208\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1208\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1220\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    828\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    830\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    831\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    832\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    850\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    514\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    515\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:456\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    453\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    454\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 456\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:469\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    468\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 469\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:381\u001b[0m, in \u001b[0;36mXLMRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    380\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 381\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import time\n",
    "model = ...\n",
    "train_dataloader\n",
    "optimizer\n",
    "scheduler\n",
    "results5  = Trainer(model, train_dataloader, epochs, batch_size, device, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6acae17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps per epoch:  0\n",
      "training on epoch:  0\n",
      "average training loss: 1.8568\n",
      "training on epoch:  1\n",
      "average training loss: 0.7086\n",
      "training on epoch:  2\n",
      "average training loss: 1.5016\n",
      "training on epoch:  3\n",
      "average training loss: 1.5525\n",
      "training on epoch:  4\n",
      "average training loss: 1.1286\n",
      "training on epoch:  5\n",
      "average training loss: 0.7272\n",
      "training on epoch:  6\n",
      "average training loss: 0.8362\n",
      "training on epoch:  7\n",
      "average training loss: 0.9033\n",
      "training on epoch:  8\n",
      "average training loss: 0.9136\n",
      "training on epoch:  9\n",
      "average training loss: 0.6585\n",
      "training on epoch:  10\n",
      "average training loss: 0.5085\n",
      "training on epoch:  11\n",
      "average training loss: 0.5193\n",
      "training on epoch:  12\n",
      "average training loss: 0.4791\n",
      "training on epoch:  13\n",
      "average training loss: 0.4123\n",
      "training on epoch:  14\n",
      "average training loss: 0.5101\n",
      "training on epoch:  15\n",
      "average training loss: 0.4043\n",
      "training on epoch:  16\n",
      "average training loss: 0.3794\n",
      "training on epoch:  17\n",
      "average training loss: 0.3867\n",
      "training on epoch:  18\n",
      "average training loss: 0.3324\n",
      "training on epoch:  19\n",
      "average training loss: 0.3288\n",
      "training on epoch:  20\n",
      "average training loss: 0.3552\n",
      "training on epoch:  21\n",
      "average training loss: 0.3463\n",
      "training on epoch:  22\n",
      "average training loss: 0.3830\n",
      "training on epoch:  23\n",
      "average training loss: 0.4093\n",
      "training on epoch:  24\n",
      "average training loss: 0.3646\n",
      "training on epoch:  25\n",
      "average training loss: 0.3341\n",
      "training on epoch:  26\n",
      "average training loss: 0.3435\n",
      "training on epoch:  27\n",
      "average training loss: 0.3457\n",
      "training on epoch:  28\n",
      "average training loss: 0.3122\n",
      "training on epoch:  29\n",
      "average training loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "import time\n",
    "results5  = Trainer(model, train_dataloader, epochs, batch_size, device, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9897efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 62.11 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "\n",
    "# evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Add batch to device\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3c75246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da45a9ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      5\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m target_num \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_test)\n\u001b[1;32m     10\u001b[0m final_prediction_list \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mconcatenate(predictions))\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/preprocessing/_label.py:97\u001b[0m, in \u001b[0;36mLabelEncoder.fit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        Fitted label encoder.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m _unique(y)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/utils/validation.py:1220\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \n\u001b[1;32m   1196\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;124;03m    If `y` is not a 1D array or a 2D array with a single row or column.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[0;32m-> 1220\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y_test)\n",
    "target_num = le.transform(y_test)\n",
    "\n",
    "final_prediction_list = le.inverse_transform(np.concatenate(predictions))\n",
    "final_truelabel_list = le.inverse_transform(np.concatenate(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffd908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ts = Trainer(model, test_dataloader, epochs, batch_size, device, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db462697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps per epoch:  0\n",
      "training on epoch:  0\n",
      "average training loss: 3.1658\n",
      "training on epoch:  1\n",
      "average training loss: 4.9523\n",
      "training on epoch:  2\n",
      "average training loss: 5.2118\n",
      "training on epoch:  3\n",
      "average training loss: 9.5699\n",
      "training on epoch:  4\n",
      "average training loss: 7.1408\n",
      "training on epoch:  5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mval_loss \u001b[38;5;66;03m# an improvement is considered if the score is higher\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m handler \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, score_function\u001b[38;5;241m=\u001b[39mscore_function, trainer\u001b[38;5;241m=\u001b[39m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[20], line 56\u001b[0m, in \u001b[0;36mTrainer\u001b[0;34m(model, train_dataloader, epochs, batch_size, device, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     53\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# total loss\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# clip the norm of the gradients to 1.0.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)         \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "# create engine object\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['nll']\n",
    "    \n",
    "    return -val_loss # an improvement is considered if the score is higher\n",
    "\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=Trainer(model, train_dataloader, epochs, batch_size, device, optimizer, scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# d = pd.read_csv('../results/transformer_model_loss.csv')\n",
    "df = pd.DataFrame({'2-epochs': pd.Series(results3),\n",
    "                  '13-epochs': pd.Series(results4),\n",
    "                  '18-epochs': pd.Series(results5)})\n",
    "# df = pd.concat([d, dd], axis=1)\n",
    "df\n",
    "# df = df.drop(columns='Unnamed: 0').iloc[:,[0,1,2,4,3]]\n",
    "print(df)\n",
    "df.to_csv('../results/model_loss2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe3d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/szfgpm5s0tn_frclv0gl7m2c0000gr/T/ipykernel_67385/229306452.py:4: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot model loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# epoch = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "def plot_loss(epoch, results, name):\n",
    "    \n",
    "    # plot\n",
    "    plt.plot(epoch, results, linestyle='--',color='orange')\n",
    "    # title\n",
    "    plt.title('Model loss')\n",
    "    # x label\n",
    "    plt.xlabel('Epochs')\n",
    "    # y label\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    return plt.savefig(fname=name, dpi=800), plt.show()\n",
    "\n",
    "# plot\n",
    "epoch = range(0,epochs)\n",
    "\n",
    "plot_loss(epoch, results, name='../results/Loss_epochs_30_ts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "def Eval(model, test_dataloader, device, ):\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "\n",
    "# evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('mpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten() # predicitions with the highest probability\n",
    "    \n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388dbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_values, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19637b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79635f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate list of arrays\n",
    "\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "final_truelabel_list = np.concatenate(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cr = classification_report(final_truelabel_list, \n",
    "                           final_prediction_list)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bba0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing loss values\n",
    "\n",
    "loss = pd.DataFrame({'lr: 0.001': loss_values, \n",
    "                    'lr: 0.01': loss_values_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aae6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineplot\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x_epoch = list(range(0, epochs))\n",
    "\n",
    "y_loss = loss_values\n",
    "\n",
    "plt.plot(x_epoch, y_loss, color='#881111', linestyle=':', linewidth=1, marker='.', label='learning rate: 0.001')\n",
    "\n",
    "y_loss_2 = loss_values_2\n",
    "\n",
    "plt.plot(x_epoch, y_loss_2, 'b--', label='learning rate: 0.01')\n",
    "\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('plot.png')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d127d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we might train the neural network with mini-batch (stochastic) gradient descent, which means that we split the original training dataset into =/\n",
    "#  batches, where \n",
    "#      is the size of the original dataset and \n",
    "#      is the batch size (typical numbers are 32 or 64). So, if you have, say, =10000\n",
    "#  and =32\n",
    "# , then we have =312\n",
    "#  mini-batches; so, for each epoch, you will perform 312 gradient steps, one for each mini-batch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
