{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training of text classiffiers using logreg, svm, mlp \n",
    "# Violeta Berdejo-Espinola, Akos Hajas, Nan Ye\n",
    "# November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mpu scikit-learn imblearn embetter sentence_transformers matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpu\n",
    "\n",
    "# raw corpus\n",
    "\n",
    "corpus_raw = mpu.io.read('../data/corpus_raw.pickle')\n",
    "corpus_raw_long = mpu.io.read('../data/corpus_raw_long.pickle')\n",
    "\n",
    "x_raw = corpus_raw\n",
    "x_raw_long = corpus_raw_long\n",
    "\n",
    "# clean corpus\n",
    "\n",
    "corpus = mpu.io.read('../data/corpus_clean.pickle')\n",
    "corpus_long = mpu.io.read('../data/corpus_clean_long.pickle')\n",
    "\n",
    "x = corpus\n",
    "x_long = corpus_long\n",
    "\n",
    "# pos, negs\n",
    "\n",
    "pos = mpu.io.read('../data/pos.pickle')\n",
    "neg = mpu.io.read('../data/neg.pickle')\n",
    "y = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_class_0 = len(x) / (len(neg) * 2) \n",
    "weight_for_class_1 = len(x) / (len(pos) * 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_train_long, x_test_long, y_train_long, y_test_long = train_test_split(x_long, y, test_size=0.20, random_state=42)\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_raw, y, test_size=0.20, random_state=42)\n",
    "x_train_r_long, x_test_r_long, y_train_r_long, y_test_r_long = train_test_split(x_raw_long, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for i in y_test:\n",
    "    counter[i] +=1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate feature extractors, embedding models, resamplers, models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # uses one-dim array of strings ~ shape (n,)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # returns arrays\n",
    "\n",
    "vect_cv = CountVectorizer()\n",
    "vect_tfidf = TfidfVectorizer()\n",
    "\n",
    "model_mpnet = 'paraphrase-multilingual-mpnet-base-v2'\n",
    "model_distill = 'distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_weight = LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)\n",
    "svm = SVC(kernel='linear')\n",
    "svm_weight = SVC(kernel='linear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, probability=True)\n",
    "mlp = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "mlp_t = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(5,), learning_rate='invscaling',learning_rate_init=1, solver='sgd', random_state=42, max_iter=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline \n",
    "\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "def train_eval_tf_tfidf(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, feature_extractor, balanced):\n",
    "        \n",
    "        pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                             (\"estimator\", estimator)\n",
    "                            ])\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') # cross val splits the data and then applies the pipeline steps\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': pipeline['estimator'],\n",
    "            'Feature_extraction': pipeline['vectorizer'],\n",
    "            'Weighting': 'Weighted' if balanced else 'None',\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for estimator in [logreg, svm]:\n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, False))\n",
    "            \n",
    "        for estimator in [logreg_weight, svm_weight]: \n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "def train_eval_embeddings(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, balanced):\n",
    "        \n",
    "        pipeline = make_pipeline(\n",
    "            SentenceEncoder(embedding_model),\n",
    "            estimator\n",
    "        )\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': estimator,\n",
    "            'Feature_extraction': embedding_model,\n",
    "            'Weighting': 'Weighted' if balanced else None,\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for embedding_model in [model_mpnet, model_distill]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp, mlp_t]:\n",
    "                all_scores.append(run_estimator(estimator, False))\n",
    "                \n",
    "            for estimator in [logreg_weight, svm_weight]: \n",
    "                all_scores.append(run_estimator(estimator, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "def train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for resampler in [rus, ros, ada]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "        \n",
    "                pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                                    (\"resampler\", resampler),\n",
    "                                    (\"estimator\", estimator)\n",
    "                                    ])\n",
    "        \n",
    "                y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "                pipeline.fit(x_train, y_train)\n",
    "                \n",
    "                y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "                y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "                scores = {\n",
    "                    'Classifier': pipeline['estimator'],\n",
    "                    'Feature_extraction': pipeline['vectorizer'],\n",
    "                    'Weighting': pipeline['resampler'],\n",
    "                    'CV': kfold,\n",
    "                    'Text_length': text_length,\n",
    "                    'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "                    'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "                    'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "                    'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "                    'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "                    'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "                    'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "                }\n",
    "    \n",
    "                all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "def train_eval_embedding_resampled(x_train, y_train, x_test, y_test, text_length, kfold, embed_model):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embed_model),\n",
    "        RandomOverSampler(random_state=42, sampling_strategy='not majority'),\n",
    "        MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "    )\n",
    "                                \n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': mlp,\n",
    "        'Feature_extraction': embed_model,\n",
    "        'Weighting': ros,\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "    }\n",
    "\n",
    "    all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "df1 = pd.DataFrame(train_eval_tf_tfidf(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df2 = pd.DataFrame(train_eval_tf_tfidf(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "df3 = pd.DataFrame(train_eval_embeddings(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2))\n",
    "df4 = pd.DataFrame(train_eval_embeddings(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "df5 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df6 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "df7 = pd.DataFrame(train_eval_embedding_resampled(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2, model_mpnet))\n",
    "df8 = pd.DataFrame(train_eval_embedding_resampled(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2, model_mpnet))\n",
    "\n",
    "df9 = pd.DataFrame(train_eval_embedding_resampled(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2, model_distill))\n",
    "df10 = pd.DataFrame(train_eval_embedding_resampled(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2, model_distill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cocatenate model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "res = res.sort_values(by='Recall_tr_cv', ascending=False).reset_index(drop=True)\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.to_csv('../results/preliminary/model_results_dec2024_embedd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# predict probabilities and calculate model loss\n",
    "# log_likelihood = y_test*np.log(y_pred) + (1-y_test)*np.log(1-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_best_model(x_train, y_train, x_test, y_test, text_length, kfold, embedding_model, random_state):\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embedding_model),\n",
    "        LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=random_state)\n",
    "    )\n",
    "\n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') \n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': 'Log_reg',\n",
    "        'Feature_extraction': embedding_model,\n",
    "        'Weighting': 'Weighted',\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'Solver': 'Liblinear',\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "    \n",
    "    # train set\n",
    "    y_pred_tr = pipeline.predict_proba(x_train) # predict_proba returns probabilities of a classification label\n",
    "    logloss_tr = log_loss(y_train, y_pred_tr) \n",
    "\n",
    "    # test set\n",
    "    y_pred_ts = pipeline.predict_proba(x_test)  \n",
    "    logloss_ts = log_loss(y_test, y_pred_ts)\n",
    "    \n",
    "    print(f'loss training set: {logloss_tr}, \\nloss test set {logloss_ts}')\n",
    "    print(f'confusion matrix train set:\\n{confusion_matrix(y_train, pipeline.predict(x_train))}')\n",
    "    print(f'confusion matrix test set:\\n{confusion_matrix(y_test, pipeline.predict(x_test))}') \n",
    " \n",
    "    return scores, y_pred_ts, logloss_tr, logloss_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model \n",
    "\n",
    "best_model = train_eval_best_model(x_train_r, y_train_r, x_test_r, y_test_r, 'Title_Abstract', 2, model_distill, 42)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigating performance on different train-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on a few different train-test partitions, then report the average with the standard error.\n",
    "# I should see greater performance with more data, but also lower variance across the different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seed24 = train_eval_best_model(x_train_r, y_train_r, x_test_r, y_test_r, 'Title_Abstract', 2, model_distill, 24)\n",
    "m_seed36 = train_eval_best_model(x_train_r, y_train_r, x_test_r, y_test_r, 'Title_Abstract', 2, model_distill, 36)\n",
    "m_seed64 = train_eval_best_model(x_train_r, y_train_r, x_test_r, y_test_r, 'Title_Abstract', 2, model_distill, 64)\n",
    "m_seed128 = train_eval_best_model(x_train_r, y_train_r, x_test_r, y_test_r, 'Title_Abstract', 2, model_distill, 128)\n",
    "\n",
    "m_seeds = [m_seed24[2], m_seed36[2], m_seed64[2], m_seed128[2], best_model[2]]\n",
    "\n",
    "from statistics import stdev\n",
    "\n",
    "std_dev = stdev(m_seeds)\n",
    "std_dev # logloss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot predicted probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_ts_p = best_model[1][:,1] # subset class of interest --> 1d array\n",
    "y_pred_ts_n = best_model[1][:,0]\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(y_pred_ts_n, bins=50, label='Negatives')\n",
    "plt.hist(y_pred_ts_p, bins=50, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Predicted probabilities', fontsize=15)\n",
    "plt.ylabel('Number of examples', fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.tick_params(axis='both', labelsize=15, pad=5)\n",
    "plt.show() \n",
    "# plt.savefig('../results/logreg_svm_mlp/predicted_proba_logreg_ts.png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict probabilities, compute auc score and roc curve \n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_auc_roc(estimator, embedding_model, x_train, y_train, x_test, y_test, random_state):\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embedding_model),\n",
    "        LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=random_state)\n",
    "    )\n",
    "    \n",
    "    # y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') \n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    pred_prob = pipeline.predict_proba(x_test)\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, pred_prob[:,1])\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "    return auc_score, fpr, tpr, pred_prob, y_pred\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "auc_lr_weight_distill, fpr_lr_weight_distill, tpr_lr_weight_distill, y_pred_proba_lr_weight_distill, y_pred_lr_weight__distill= get_auc_roc(logreg_weight, model_distill, x_train_r, y_train_r, x_test_r, y_test_r, 42)\n",
    "auc_lr_weight_mpnet, fpr_lr_weight_mpnet, tpr_lr_weight_mpnet, y_pred_proba_lr_weight_mpnet, y_pred_lr_weight_mpnet= get_auc_roc(logreg_weight, model_mpnet, x_train_r, y_train_r, x_test_r, y_test_r, 42)\n",
    "auc_svm_weight_distill, fpr_svm_weight_distill, tpr_svm_weight_distill, y_pred_proba_svm_weight_distill, y_pred_svm_weight_distill= get_auc_roc(svm_weight, model_distill, x_train_r, y_train_r, x_test_r, y_test_r, 42)\n",
    "auc_svm_weight_mpnet, fpr_svm_weight_mpnet, tpr_svm_weight_mpnet, y_pred_proba_svm_weight_mpnet, y_pred_svm_weight_mpnet= get_auc_roc(svm_weight, model_mpnet, x_train_r, y_train_r, x_test_r, y_test_r, 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr_lr_weight_distill, tpr_lr_weight_distill, linestyle='--',color='#bbca', label='Logistic Regression - weighted - distill embeddings')\n",
    "plt.plot(fpr_svm_weight_distill, tpr_svm_weight_distill, linestyle='--',color='blue', label='SVM - weighted - distill embeddings')\n",
    "plt.plot(fpr_lr_weight_mpnet, tpr_lr_weight_mpnet, linestyle='--',color='gray', label='Logistic Regression - weighted - mpnet embeddings')\n",
    "plt.plot(fpr_svm_weight_mpnet, tpr_svm_weight_mpnet, linestyle='--',color='red', label='SVM - weighted - mpnet embeddings')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='gray')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('../results/ROC.png',dpi=800)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x df with df containing text to explore \n",
    "# missclassification of false positive instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "dat_pred_label = pd.DataFrame(best_model[1], columns=['neg_label', 'pos_label'])\n",
    "dat_pred_label['y_true'] = y_test\n",
    "dat_pred_label\n",
    "\n",
    "# assign predicted labels to examples\n",
    "\n",
    "def get_prediction_label(row):\n",
    "    if row[\"y_true\"] == 0:\n",
    "        return 'fp' if row['neg_label'] < 0.5 else 'tn'\n",
    "    else:\n",
    "        return 'tp' if row['pos_label'] > 0.5 else 'fn'\n",
    "\n",
    "dat_pred_label['prediction_label'] = dat_pred_label.apply(get_prediction_label, axis=1)\n",
    "\n",
    "dat_pred_label = dat_pred_label.merge(x_test_df, left_index=True, right_index=True)\n",
    "# dat_pred_label.to_csv('../results/preliminary/error_analysis_predictions_with_tetx.csv')\n",
    "\n",
    "fp_examples = dat_pred_label[dat_pred_label['prediction_label'] == 'fp']\n",
    "fp_examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
