{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training of text classiffiers using logreg, svm, mlp \n",
    "# Violeta Berdejo-Espinola\n",
    "# November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mpu scikit-learn imblearn embetter sentence_transformers matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpu\n",
    "\n",
    "# raw corpus\n",
    "\n",
    "corpus_raw = mpu.io.read('../data/corpus_raw.pickle')\n",
    "corpus_raw_long = mpu.io.read('../data/corpus_raw_long.pickle')\n",
    "\n",
    "x_raw = corpus_raw\n",
    "x_raw_long = corpus_raw_long\n",
    "\n",
    "# clean corpus\n",
    "\n",
    "corpus = mpu.io.read('../data/corpus_clean.pickle')\n",
    "corpus_long = mpu.io.read('../data/corpus_clean_long.pickle')\n",
    "\n",
    "x = corpus\n",
    "x_long = corpus_long\n",
    "\n",
    "# pos, negs\n",
    "\n",
    "pos = mpu.io.read('../data/pos.pickle')\n",
    "neg = mpu.io.read('../data/neg.pickle')\n",
    "y = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_train_long, x_test_long, y_train_long, y_test_long = train_test_split(x_long, y, test_size=0.20, random_state=42)\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_raw, y, test_size=0.20, random_state=42)\n",
    "x_train_r_long, x_test_r_long, y_train_r_long, y_test_r_long = train_test_split(x_raw_long, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for x in y_test:\n",
    "    counter[x] +=1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate feature extractors, embedding models, resamplers, models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # uses one-dim array of strings ~ shape (n,)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # returns arrays\n",
    "\n",
    "vect_cv = CountVectorizer()\n",
    "vect_tfidf = TfidfVectorizer()\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_mpnet = 'paraphrase-multilingual-mpnet-base-v2'\n",
    "model_distill = 'distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "weight_for_class_0 = len(x) / (len(neg) * 2) \n",
    "weight_for_class_1 = len(x) / (len(pos) * 2) \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_weight = LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)\n",
    "svm = SVC(kernel='linear')\n",
    "svm_weight = SVC(kernel='linear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, probability=True)\n",
    "mlp = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline \n",
    "\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "def train_eval_tf_tfidf(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, feature_extractor, balanced):\n",
    "        \n",
    "        pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                             (\"estimator\", estimator)\n",
    "                            ])\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') # cross val splits the data and then applies the pipeline steps\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': pipeline['estimator'],\n",
    "            'Feature_extraction': pipeline['vectorizer'],\n",
    "            'Weighting': 'Weighted' if balanced else None,\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for estimator in [logreg, svm]:\n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, False))\n",
    "            \n",
    "        for estimator in [logreg_weight, svm_weight]: \n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "def train_eval_embeddings(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, balanced):\n",
    "        \n",
    "        pipeline = make_pipeline(\n",
    "            SentenceEncoder(embedding_model),\n",
    "            estimator\n",
    "        )\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': estimator,\n",
    "            'Feature_extraction': embedding_model,\n",
    "            'Weighting': 'Weighted' if balanced else None,\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for embedding_model in [model_mpnet, model_distill]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "                all_scores.append(run_estimator(estimator, False))\n",
    "                \n",
    "            for estimator in [logreg_weight, svm_weight]: \n",
    "                all_scores.append(run_estimator(estimator, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "def train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for resampler in [rus, ros, ada]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "        \n",
    "                pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                                    (\"resampler\", resampler),\n",
    "                                    (\"estimator\", estimator)\n",
    "                                    ])\n",
    "        \n",
    "                y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "                pipeline.fit(x_train, y_train)\n",
    "                \n",
    "                y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "                y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "                scores = {\n",
    "                    'Classifier': pipeline['estimator'],\n",
    "                    'Feature_extraction': pipeline['feature_extractor'],\n",
    "                    'Weighting': pipeline['resampler'],\n",
    "                    'CV': kfold,\n",
    "                    'Text_length': text_length,\n",
    "                    'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "                    'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "                    'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "                    'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "                    'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "                    'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "                    'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "                }\n",
    "    \n",
    "                all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "def train_eval_embedding_resampled(x_train, y_train, x_test, y_test, text_length, kfold, embed_model):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embed_model),\n",
    "        RandomOverSampler(random_state=42, sampling_strategy='not majority'),\n",
    "        MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "    )\n",
    "                                \n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': mlp,\n",
    "        'Feature_extraction': embed_model,\n",
    "        'Weighting': ros,\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "    }\n",
    "\n",
    "    all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "df1 = pd.DataFrame(train_eval_tf_tfidf(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df2 = pd.DataFrame(train_eval_tf_tfidf(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "df3 = pd.DataFrame(train_eval_embeddings(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df4 = pd.DataFrame(train_eval_embeddings(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "df5 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df6 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "df7 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_mpnet))\n",
    "df8 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract_Main',2, model_mpnet))\n",
    "\n",
    "df9 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_distill))\n",
    "df10 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_distill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cocatenate model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "res = results.sort_values(by='Recall_tr', ascending=False).reset_index(drop=True)\n",
    "res\n",
    "# res.to_csv('../results/logreg_svm_mlp/model_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# predict probabilities and calculate model loss\n",
    "# log_likelihood = y_test*np.log(y_pred) + (1-y_test)*np.log(1-y_pred)\n",
    "\n",
    "# (tn, fp, fn, tp)\n",
    "#true negatives, false positives\n",
    "#false negatives, true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_best_model(x_train, y_train, x_test, y_test, text_length, kfold, embedding_model, solver, random_state):\n",
    "    \n",
    "    all_scores = []\n",
    "        \n",
    "    for estimator in [LogisticRegression(solver=solver, class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)]: \n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            SentenceEncoder(embedding_model),\n",
    "            estimator\n",
    "        )\n",
    "\n",
    "        scores = []\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') \n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        scores = {\n",
    "            'Classifier': estimator,\n",
    "            'Feature_extraction': embedding_model,\n",
    "            'Weighting': 'Weighted',\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'Solver': solver,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "            }\n",
    "        \n",
    "        # train set\n",
    "        y_pred_tr = pipeline.predict_proba(x_train) # predict_proba returns probabilities of a classification label\n",
    "        logloss_tr = log_loss(y_train, y_pred_tr) \n",
    "\n",
    "        # test set\n",
    "        y_pred_ts = pipeline.predict_proba(x_test)  \n",
    "        logloss_ts = log_loss(y_test, y_pred_ts)\n",
    "\n",
    "        print(f'loss training set: {logloss_tr}, \\nloss test set {logloss_ts}')\n",
    "        print(f'confusion matrix train set:\\n{confusion_matrix(y_train, pipeline.predict(x_train))}')\n",
    "        print(f'confusion matrix test set:\\n{confusion_matrix(y_test, pipeline.predict(x_test))}') \n",
    "        \n",
    "        all_scores.append(scores)\n",
    "\n",
    "    return all_scores, y_pred_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_lbfgs_seed_36 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_mpnet, 'lbfgs', 36)\n",
    "mpnet_lbfgs_seed_36 # seed 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_lbfgs_seed_42 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'lbfgs', 42)\n",
    "distill_lbfgs_seed_42 # seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_lbfgs_seed_42= train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2 model_distill, 'liblinear', 42)\n",
    "distill_lbfgs_seed_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_liblinear_seed_36 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'liblinear', 36)\n",
    "distill_liblinear_seed_36 # seed 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigating performance on different train-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on a few different train-test partitions, then report the average with the standard error.\n",
    "# I should see greater performance with more data, but also lower variance across the different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seed24 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'liblinear', 24)\n",
    "m_seed36 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'liblinear', 36)\n",
    "m_seed64 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'liblinear', 64)\n",
    "m_seed128 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 'liblinear', 128)\n",
    "\n",
    "m_seeds = pd.concat([m_seed24, m_seed36, m_seed64, m_seed128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x df with df containing text to explore \n",
    "# missclassification of false positive instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log reg\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "dat_pred_label = pd.DataFrame(distill_liblinear[1], columns=['neg_label', 'pos_label'])\n",
    "dat_pred_label['y_true'] = y_test\n",
    "dat_pred_label\n",
    "\n",
    "# assign predicted labels to examples\n",
    "\n",
    "def get_prediction_label(row):\n",
    "    if row[\"y_true\"] == 0:\n",
    "        return 'fp' if row['neg_label'] < 0.5 else 'tn'\n",
    "    else:\n",
    "        return 'tp' if row['pos_label'] > 0.5 else 'fn'\n",
    "\n",
    "dat_pred_label['prediction_label'] = dat_pred_label.apply(get_prediction_label, axis=1)\n",
    "\n",
    "dat_pred_label = dat_pred_label.merge(x_test_df, left_index=True, right_index=True)\n",
    "dat_pred_label.to_csv('../results/logreg_svm_mlp/error_analysis_predictions_with_tetx.csv')\n",
    "\n",
    "fp_examples = dat_pred_label[dat_pred_label['prediction_label'] == 'fp']\n",
    "fp_examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
