{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training of text classiffiers using logreg, svm, mlp \n",
    "# Violeta Berdejo-Espinola\n",
    "# November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mpu in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (0.23.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (1.3.0)\n",
      "Requirement already satisfied: imblearn in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (0.0)\n",
      "Requirement already satisfied: embetter in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (0.6.4)\n",
      "Requirement already satisfied: sentence_transformers in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (3.7.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (8.0.6)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from imblearn) (0.12.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from embetter) (2.0.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from embetter) (5.6.3)\n",
      "Requirement already satisfied: skops>=0.8.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from embetter) (0.10.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (2.4.0.dev20240317)\n",
      "Requirement already satisfied: nltk in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (0.26.1)\n",
      "Requirement already satisfied: Pillow in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sentence_transformers) (10.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (6.23.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (8.13.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: filelock in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: appnope in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: psutil in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: backcall in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from pandas>=1.0.0->embetter) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from pandas>=1.0.0->embetter) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tabulate>=0.8.8 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from skops>=0.8.0->embetter) (0.9.0)\n",
      "Requirement already satisfied: sympy in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.20.1)\n",
      "Requirement already satisfied: click in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/uqvberde/Library/Python/3.11/lib/python/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mpu scikit-learn imblearn embetter sentence_transformers matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpu\n",
    "\n",
    "# raw corpus\n",
    "\n",
    "corpus_raw = mpu.io.read('../data/corpus_raw.pickle')\n",
    "corpus_raw_long = mpu.io.read('../data/corpus_raw_long.pickle')\n",
    "\n",
    "x_raw = corpus_raw\n",
    "x_raw_long = corpus_raw_long\n",
    "\n",
    "# clean corpus\n",
    "\n",
    "corpus = mpu.io.read('../data/corpus_clean.pickle')\n",
    "corpus_long = mpu.io.read('../data/corpus_clean_long.pickle')\n",
    "\n",
    "x = corpus\n",
    "x_long = corpus_long\n",
    "\n",
    "# pos, negs\n",
    "\n",
    "pos = mpu.io.read('../data/pos.pickle')\n",
    "neg = mpu.io.read('../data/neg.pickle')\n",
    "y = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_class_0 = len(x) / (len(neg) * 2) \n",
    "weight_for_class_1 = len(x) / (len(pos) * 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_train_long, x_test_long, y_train_long, y_test_long = train_test_split(x_long, y, test_size=0.20, random_state=42)\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_raw, y, test_size=0.20, random_state=42)\n",
    "x_train_r_long, x_test_r_long, y_train_r_long, y_test_r_long = train_test_split(x_raw_long, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 991, 1: 13})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for i in y_test:\n",
    "    counter[i] +=1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate feature extractors, embedding models, resamplers, models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # uses one-dim array of strings ~ shape (n,)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # returns arrays\n",
    "\n",
    "vect_cv = CountVectorizer()\n",
    "vect_tfidf = TfidfVectorizer()\n",
    "\n",
    "model_mpnet = 'paraphrase-multilingual-mpnet-base-v2'\n",
    "model_distill = 'distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_weight = LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)\n",
    "svm = SVC(kernel='linear')\n",
    "svm_weight = SVC(kernel='linear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, probability=True)\n",
    "mlp = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline \n",
    "\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "def train_eval_tf_tfidf(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, feature_extractor, balanced):\n",
    "        \n",
    "        pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                             (\"estimator\", estimator)\n",
    "                            ])\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') # cross val splits the data and then applies the pipeline steps\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': pipeline['estimator'],\n",
    "            'Feature_extraction': pipeline['vectorizer'],\n",
    "            'Weighting': 'Weighted' if balanced else 'None',\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for estimator in [logreg, svm]:\n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, False))\n",
    "            \n",
    "        for estimator in [logreg_weight, svm_weight]: \n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "def train_eval_embeddings(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, balanced):\n",
    "        \n",
    "        pipeline = make_pipeline(\n",
    "            SentenceEncoder(embedding_model),\n",
    "            estimator\n",
    "        )\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': estimator,\n",
    "            'Feature_extraction': embedding_model,\n",
    "            'Weighting': 'Weighted' if balanced else None,\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for embedding_model in [model_mpnet, model_distill]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "                all_scores.append(run_estimator(estimator, False))\n",
    "                \n",
    "            for estimator in [logreg_weight, svm_weight]: \n",
    "                all_scores.append(run_estimator(estimator, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "def train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for resampler in [rus, ros, ada]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "        \n",
    "                pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                                    (\"resampler\", resampler),\n",
    "                                    (\"estimator\", estimator)\n",
    "                                    ])\n",
    "        \n",
    "                y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "                pipeline.fit(x_train, y_train)\n",
    "                \n",
    "                y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "                y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "                scores = {\n",
    "                    'Classifier': pipeline['estimator'],\n",
    "                    'Feature_extraction': pipeline['vectorizer'],\n",
    "                    'Weighting': pipeline['resampler'],\n",
    "                    'CV': kfold,\n",
    "                    'Text_length': text_length,\n",
    "                    'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "                    'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "                    'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "                    'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "                    'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "                    'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "                    'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "                }\n",
    "    \n",
    "                all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "def train_eval_embedding_resampled(x_train, y_train, x_test, y_test, text_length, kfold, embed_model):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embed_model),\n",
    "        RandomOverSampler(random_state=42, sampling_strategy='not majority'),\n",
    "        MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "    )\n",
    "                                \n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': mlp,\n",
    "        'Feature_extraction': embed_model,\n",
    "        'Weighting': ros,\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "    }\n",
    "\n",
    "    all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "df1 = pd.DataFrame(train_eval_tf_tfidf(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df2 = pd.DataFrame(train_eval_tf_tfidf(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "df3 = pd.DataFrame(train_eval_embeddings(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df4 = pd.DataFrame(train_eval_embeddings(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/uqvberde/Library/Python/3.11/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "df5 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df6 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "df7 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_mpnet))\n",
    "df8 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract_Main',2, model_mpnet))\n",
    "\n",
    "df9 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_distill))\n",
    "df10 = pd.DataFrame(train_eval_embedding_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2, model_distill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cocatenate model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Feature_extraction</th>\n",
       "      <th>Weighting</th>\n",
       "      <th>CV</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>F1_tr_cv</th>\n",
       "      <th>F1_tr</th>\n",
       "      <th>F1_ts</th>\n",
       "      <th>Precision_tr_cv</th>\n",
       "      <th>Precision_tr</th>\n",
       "      <th>Precision_ts</th>\n",
       "      <th>Recall_tr_cv</th>\n",
       "      <th>Recall_tr</th>\n",
       "      <th>Recall_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier(activation='logistic', batch_siz...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>RandomUnderSampler(random_state=42, sampling_s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLPClassifier(activation='logistic', batch_siz...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>RandomUnderSampler(random_state=42, sampling_s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract_Main</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLPClassifier(activation='logistic', batch_siz...</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>RandomUnderSampler(random_state=42, sampling_s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier(activation='logistic', batch_siz...</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>RandomUnderSampler(random_state=42, sampling_s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract_Main</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>RandomUnderSampler(random_state=42, sampling_s...</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>MLPClassifier(activation='logistic', batch_siz...</td>\n",
       "      <td>distiluse-base-multilingual-cased-v1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract_Main</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>distiluse-base-multilingual-cased-v1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract_Main</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>distiluse-base-multilingual-cased-v1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract_Main</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>distiluse-base-multilingual-cased-v1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Title_Abstract</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Classifier  \\\n",
       "0   MLPClassifier(activation='logistic', batch_siz...   \n",
       "1   MLPClassifier(activation='logistic', batch_siz...   \n",
       "2   MLPClassifier(activation='logistic', batch_siz...   \n",
       "3   MLPClassifier(activation='logistic', batch_siz...   \n",
       "4   LogisticRegression(random_state=42, solver='li...   \n",
       "..                                                ...   \n",
       "71  MLPClassifier(activation='logistic', batch_siz...   \n",
       "72                               SVC(kernel='linear')   \n",
       "73  LogisticRegression(random_state=42, solver='li...   \n",
       "74  LogisticRegression(random_state=42, solver='li...   \n",
       "75                               SVC(kernel='linear')   \n",
       "\n",
       "                      Feature_extraction  \\\n",
       "0                      TfidfVectorizer()   \n",
       "1                      TfidfVectorizer()   \n",
       "2                      CountVectorizer()   \n",
       "3                      CountVectorizer()   \n",
       "4                      TfidfVectorizer()   \n",
       "..                                   ...   \n",
       "71  distiluse-base-multilingual-cased-v1   \n",
       "72  distiluse-base-multilingual-cased-v1   \n",
       "73  distiluse-base-multilingual-cased-v1   \n",
       "74                     TfidfVectorizer()   \n",
       "75  distiluse-base-multilingual-cased-v1   \n",
       "\n",
       "                                            Weighting  CV  \\\n",
       "0   RandomUnderSampler(random_state=42, sampling_s...   2   \n",
       "1   RandomUnderSampler(random_state=42, sampling_s...   2   \n",
       "2   RandomUnderSampler(random_state=42, sampling_s...   2   \n",
       "3   RandomUnderSampler(random_state=42, sampling_s...   2   \n",
       "4   RandomUnderSampler(random_state=42, sampling_s...   2   \n",
       "..                                                ...  ..   \n",
       "71                                               None   2   \n",
       "72                                               None   2   \n",
       "73                                               None   2   \n",
       "74                                               None   2   \n",
       "75                                               None   2   \n",
       "\n",
       "            Text_length  F1_tr_cv  F1_tr  F1_ts  Precision_tr_cv  \\\n",
       "0        Title_Abstract     0.056  0.075  0.059            0.029   \n",
       "1   Title_Abstract_Main     0.056  0.075  0.059            0.029   \n",
       "2        Title_Abstract     0.065  0.091  0.072            0.034   \n",
       "3   Title_Abstract_Main     0.065  0.091  0.072            0.034   \n",
       "4        Title_Abstract     0.075  0.112  0.076            0.039   \n",
       "..                  ...       ...    ...    ...              ...   \n",
       "71  Title_Abstract_Main     0.000  0.367  0.267            0.000   \n",
       "72  Title_Abstract_Main     0.000  0.000  0.000            0.000   \n",
       "73  Title_Abstract_Main     0.000  0.000  0.000            0.000   \n",
       "74       Title_Abstract     0.000  0.000  0.000            0.000   \n",
       "75       Title_Abstract     0.000  0.000  0.000            0.000   \n",
       "\n",
       "    Precision_tr  Precision_ts  Recall_tr_cv  Recall_tr  Recall_ts  \n",
       "0          0.039         0.031         0.918      1.000      0.769  \n",
       "1          0.039         0.031         0.918      1.000      0.769  \n",
       "2          0.048         0.038         0.878      1.000      0.769  \n",
       "3          0.048         0.038         0.878      1.000      0.769  \n",
       "4          0.059         0.040         0.857      1.000      0.692  \n",
       "..           ...           ...           ...        ...        ...  \n",
       "71         1.000         1.000         0.000      0.224      0.154  \n",
       "72         0.000         0.000         0.000      0.000      0.000  \n",
       "73         0.000         0.000         0.000      0.000      0.000  \n",
       "74         0.000         0.000         0.000      0.000      0.000  \n",
       "75         0.000         0.000         0.000      0.000      0.000  \n",
       "\n",
       "[76 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "res = res.sort_values(by='Recall_tr_cv', ascending=False).reset_index(drop=True)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../results/preliminary/model_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# predict probabilities and calculate model loss\n",
    "# log_likelihood = y_test*np.log(y_pred) + (1-y_test)*np.log(1-y_pred)\n",
    "\n",
    "# (tn, fp, fn, tp)\n",
    "#true negatives, false positives\n",
    "#false negatives, true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_best_model(x_train, y_train, x_test, y_test, text_length, kfold, embedding_model, random_state):\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embedding_model),\n",
    "        LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=random_state)\n",
    "    )\n",
    "\n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') \n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': 'Log_reg',\n",
    "        'Feature_extraction': embedding_model,\n",
    "        'Weighting': 'Weighted',\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'Solver': 'Liblinear',\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "    \n",
    "    # train set\n",
    "    y_pred_tr = pipeline.predict_proba(x_train) # predict_proba returns probabilities of a classification label\n",
    "    logloss_tr = log_loss(y_train, y_pred_tr) \n",
    "\n",
    "    # test set\n",
    "    y_pred_ts = pipeline.predict_proba(x_test)  \n",
    "    logloss_ts = log_loss(y_test, y_pred_ts)\n",
    "\n",
    "    print(f'loss training set: {logloss_tr}, \\nloss test set {logloss_ts}')\n",
    "    print(f'confusion matrix train set:\\n{confusion_matrix(y_train, pipeline.predict(x_train))}')\n",
    "    print(f'confusion matrix test set:\\n{confusion_matrix(y_test, pipeline.predict(x_test))}') \n",
    " \n",
    "    return scores, y_pred_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training set: 0.12094192813919187, \n",
      "loss test set 0.14101942622176325\n",
      "confusion matrix train set:\n",
      "[[3787  179]\n",
      " [   0   49]]\n",
      "confusion matrix test set:\n",
      "[[938  53]\n",
      " [  4   9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier': 'Log_reg',\n",
       "  'Feature_extraction': 'paraphrase-multilingual-mpnet-base-v2',\n",
       "  'Weighting': 'Weighted',\n",
       "  'CV': 2,\n",
       "  'Text_length': 'Title_Abstract',\n",
       "  'Solver': 'Liblinear',\n",
       "  'F1_tr_cv': 0.214,\n",
       "  'F1_tr': 0.354,\n",
       "  'F1_ts': 0.24,\n",
       "  'Precision_tr_cv': 0.134,\n",
       "  'Precision_tr': 0.215,\n",
       "  'Precision_ts': 0.145,\n",
       "  'Recall_tr_cv': 0.531,\n",
       "  'Recall_tr': 1.0,\n",
       "  'Recall_ts': 0.692},\n",
       " array([[0.66922965, 0.33077035],\n",
       "        [0.9146951 , 0.0853049 ],\n",
       "        [0.80018461, 0.19981539],\n",
       "        ...,\n",
       "        [0.998998  , 0.001002  ],\n",
       "        [0.97490819, 0.02509181],\n",
       "        [0.52840227, 0.47159773]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnet_seed_42 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_mpnet, 42)\n",
    "mpnet_seed_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss training set: 0.18816402398979437, \n",
      "loss test set 0.20433647693199175\n",
      "confusion matrix train set:\n",
      "[[3708  258]\n",
      " [   0   49]]\n",
      "confusion matrix test set:\n",
      "[[919  72]\n",
      " [  3  10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Classifier': 'Log_reg',\n",
       "  'Feature_extraction': 'distiluse-base-multilingual-cased-v1',\n",
       "  'Weighting': 'Weighted',\n",
       "  'CV': 2,\n",
       "  'Text_length': 'Title_Abstract',\n",
       "  'Solver': 'Liblinear',\n",
       "  'F1_tr_cv': 0.169,\n",
       "  'F1_tr': 0.275,\n",
       "  'F1_ts': 0.211,\n",
       "  'Precision_tr_cv': 0.102,\n",
       "  'Precision_tr': 0.16,\n",
       "  'Precision_ts': 0.122,\n",
       "  'Recall_tr_cv': 0.49,\n",
       "  'Recall_tr': 1.0,\n",
       "  'Recall_ts': 0.769},\n",
       " array([[0.46783879, 0.53216121],\n",
       "        [0.89439193, 0.10560807],\n",
       "        [0.75219147, 0.24780853],\n",
       "        ...,\n",
       "        [0.98856338, 0.01143662],\n",
       "        [0.92281154, 0.07718846],\n",
       "        [0.31531975, 0.68468025]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_seed_42 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 42)\n",
    "distill_seed_42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_seed_36= train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2 model_distill, 36)\n",
    "distill_seed_36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_seed_36 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_mpnet, 36)\n",
    "mpnet_seed_36 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigating performance on different train-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on a few different train-test partitions, then report the average with the standard error.\n",
    "# I should see greater performance with more data, but also lower variance across the different random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_seed24 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 24)\n",
    "m_seed36 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 36)\n",
    "m_seed64 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 64)\n",
    "m_seed128 = train_eval_best_model(x_train, y_train, x_test, y_test, 'Title_Abstract', 2, model_distill, 128)\n",
    "\n",
    "m_seeds = pd.concat([m_seed24, m_seed36, m_seed64, m_seed128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine x df with df containing text to explore \n",
    "# missclassification of false positive instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_label</th>\n",
       "      <th>pos_label</th>\n",
       "      <th>y_true</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467839</td>\n",
       "      <td>0.532161</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>tiempo rendimiento costo aserrado algarrobo bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.452309</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>germinaciÃ³n supervivencia seis especie nativo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.927997</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>supervivencia crecimiento especie distinto est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>ciclo vida lombriz tierra apto vermicompostaje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.174027</td>\n",
       "      <td>0.825973</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>sustentable aprovechamiento tierro hojo bosque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>0.269882</td>\n",
       "      <td>0.730118</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>efecto gradient pastoreo ovino vegetaciÃ³n suel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.566530</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>eficiencia trampar pitlight led muestreo coleo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>0.185885</td>\n",
       "      <td>0.814115</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>abordaje participativo conservaciÃ³n modelo int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>0.294325</td>\n",
       "      <td>0.705675</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>relaciÃ³n zorro sechura pseudalopex sechurae th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.315320</td>\n",
       "      <td>0.684680</td>\n",
       "      <td>0</td>\n",
       "      <td>fp</td>\n",
       "      <td>evaluaciÃ³n restauraciÃ³n diversidad fÃºngico Ã¡re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_label  pos_label  y_true prediction_label  \\\n",
       "0      0.467839   0.532161       0               fp   \n",
       "10     0.452309   0.547691       0               fp   \n",
       "51     0.072003   0.927997       0               fp   \n",
       "56     0.466063   0.533937       0               fp   \n",
       "67     0.174027   0.825973       0               fp   \n",
       "...         ...        ...     ...              ...   \n",
       "928    0.269882   0.730118       0               fp   \n",
       "944    0.433470   0.566530       0               fp   \n",
       "963    0.185885   0.814115       0               fp   \n",
       "966    0.294325   0.705675       0               fp   \n",
       "1003   0.315320   0.684680       0               fp   \n",
       "\n",
       "                                                      0  \n",
       "0     tiempo rendimiento costo aserrado algarrobo bl...  \n",
       "10    germinaciÃ³n supervivencia seis especie nativo ...  \n",
       "51    supervivencia crecimiento especie distinto est...  \n",
       "56    ciclo vida lombriz tierra apto vermicompostaje...  \n",
       "67    sustentable aprovechamiento tierro hojo bosque...  \n",
       "...                                                 ...  \n",
       "928   efecto gradient pastoreo ovino vegetaciÃ³n suel...  \n",
       "944   eficiencia trampar pitlight led muestreo coleo...  \n",
       "963   abordaje participativo conservaciÃ³n modelo int...  \n",
       "966   relaciÃ³n zorro sechura pseudalopex sechurae th...  \n",
       "1003  evaluaciÃ³n restauraciÃ³n diversidad fÃºngico Ã¡re...  \n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log reg\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "dat_pred_label = pd.DataFrame(distill_seed_42[1], columns=['neg_label', 'pos_label'])\n",
    "dat_pred_label['y_true'] = y_test\n",
    "dat_pred_label\n",
    "\n",
    "# assign predicted labels to examples\n",
    "\n",
    "def get_prediction_label(row):\n",
    "    if row[\"y_true\"] == 0:\n",
    "        return 'fp' if row['neg_label'] < 0.5 else 'tn'\n",
    "    else:\n",
    "        return 'tp' if row['pos_label'] > 0.5 else 'fn'\n",
    "\n",
    "dat_pred_label['prediction_label'] = dat_pred_label.apply(get_prediction_label, axis=1)\n",
    "\n",
    "dat_pred_label = dat_pred_label.merge(x_test_df, left_index=True, right_index=True)\n",
    "dat_pred_label.to_csv('../results/preliminary/error_analysis_predictions_with_tetx.csv')\n",
    "\n",
    "fp_examples = dat_pred_label[dat_pred_label['prediction_label'] == 'fp']\n",
    "fp_examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
