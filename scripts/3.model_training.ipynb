{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training of text classiffiers using logreg, svm, mlp \n",
    "# Violeta Berdejo-Espinola, Akos Hajas, Nan Ye\n",
    "# November 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpu\n",
    "\n",
    "# raw corpus\n",
    "\n",
    "corpus_raw = mpu.io.read('../data/corpus_raw.pickle')\n",
    "corpus_raw_long = mpu.io.read('../data/corpus_raw_long.pickle')\n",
    "\n",
    "x_raw = [' '.join(each_document) for each_document in corpus_raw]\n",
    "x_raw_long = [' '.join(each_document) for each_document in corpus_raw_long]\n",
    "\n",
    "# clean corpus\n",
    "\n",
    "corpus = mpu.io.read('../data/corpus_clean.pickle')\n",
    "corpus_long = mpu.io.read('../data/corpus_clean_long.pickle')\n",
    "\n",
    "x = corpus\n",
    "x_long = corpus_long\n",
    "\n",
    "# pos, negs\n",
    "\n",
    "pos = mpu.io.read('../data/pos.pickle')\n",
    "neg = mpu.io.read('../data/neg.pickle')\n",
    "y = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weights\n",
    "\n",
    "weight_for_class_0 = len(x) / (len(neg) * 2) \n",
    "weight_for_class_1 = len(x) / (len(pos) * 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "x_train_long, x_test_long, y_train_long, y_test_long = train_test_split(x_long, y, test_size=0.20, random_state=42)\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_raw, y, test_size=0.20, random_state=42)\n",
    "x_train_r_long, x_test_r_long, y_train_r_long, y_test_r_long = train_test_split(x_raw_long, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for i in y_test:\n",
    "    counter[i] +=1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate feature extractors, embedding models, resamplers, models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # uses one-dim array of strings ~ shape (n,)\n",
    "from sklearn.feature_extraction.text import CountVectorizer # returns arrays\n",
    "\n",
    "vect_cv = CountVectorizer()\n",
    "vect_tfidf = TfidfVectorizer()\n",
    "\n",
    "model_mpnet = 'paraphrase-multilingual-mpnet-base-v2'\n",
    "model_distill = 'distiluse-base-multilingual-cased-v1'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='not majority')\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_weight = LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)\n",
    "svm = SVC(kernel='linear')\n",
    "svm_weight = SVC(kernel='linear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, probability=True)\n",
    "mlp = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "mlp_t = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(5,), learning_rate='invscaling',learning_rate_init=1, solver='sgd', random_state=42, max_iter=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline \n",
    "\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "def train_eval_tf_tfidf(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    def run_estimator(estimator, feature_extractor, balanced):\n",
    "        \n",
    "        pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                             (\"estimator\", estimator)\n",
    "                            ])\n",
    "    \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict') # cross val splits the data and then applies the pipeline steps\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': pipeline['estimator'],\n",
    "            'Feature_extraction': pipeline['vectorizer'],\n",
    "            'Weighting': 'Weighted' if balanced else 'None',\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for estimator in [logreg, svm]:\n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, False))\n",
    "            \n",
    "        for estimator in [logreg_weight, svm_weight]: \n",
    "            all_scores.append(run_estimator(estimator, feature_extractor, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "def train_eval_embeddings(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "\n",
    "    def run_estimator(estimator, balanced):\n",
    "        \n",
    "        pipeline = make_pipeline(\n",
    "            SentenceEncoder(embedding_model),\n",
    "            estimator\n",
    "        )\n",
    "        \n",
    "        y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "        y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "        return {\n",
    "            'Classifier': estimator,\n",
    "            'Feature_extraction': embedding_model,\n",
    "            'Weighting': 'Weighted' if balanced else None,\n",
    "            'CV': kfold,\n",
    "            'Text_length': text_length,\n",
    "            'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "            'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "            'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "            'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "            'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "            'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(y_test, y_test_pred), 3)\n",
    "        }\n",
    "\n",
    "    all_scores = []\n",
    "    \n",
    "    for embedding_model in [model_mpnet, model_distill]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp, mlp_t]:\n",
    "                all_scores.append(run_estimator(estimator, False))\n",
    "                \n",
    "            for estimator in [logreg_weight, svm_weight]: \n",
    "                all_scores.append(run_estimator(estimator, True))\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "def train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test, text_length, kfold):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    for feature_extractor in [vect_cv, vect_tfidf]:\n",
    "        \n",
    "        for resampler in [rus, ros, ada]:\n",
    "        \n",
    "            for estimator in [logreg, svm, mlp]:\n",
    "        \n",
    "                pipeline = Pipeline([(\"vectorizer\", feature_extractor),\n",
    "                                    (\"resampler\", resampler),\n",
    "                                    (\"estimator\", estimator)\n",
    "                                    ])\n",
    "        \n",
    "                y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "                pipeline.fit(x_train, y_train)\n",
    "                \n",
    "                y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "                y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "                scores = {\n",
    "                    'Classifier': pipeline['estimator'],\n",
    "                    'Feature_extraction': pipeline['vectorizer'],\n",
    "                    'Weighting': pipeline['resampler'],\n",
    "                    'CV': kfold,\n",
    "                    'Text_length': text_length,\n",
    "                    'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "                    'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "                    'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "                    'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "                    'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "                    'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "                    'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "                    'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "                }\n",
    "    \n",
    "                all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "def train_eval_embedding_resampled(x_train, y_train, x_test, y_test, text_length, kfold, embed_model):\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    pipeline = make_pipeline(\n",
    "        SentenceEncoder(embed_model),\n",
    "        RandomOverSampler(random_state=42, sampling_strategy='not majority'),\n",
    "        MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "    )\n",
    "                                \n",
    "    y_train_pred_cv = cross_val_predict(pipeline, x_train, y_train, cv=StratifiedKFold(kfold), method='predict')\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_pred = pipeline.predict(x_train)\n",
    "\n",
    "    y_test_pred = pipeline.predict(x_test)\n",
    "\n",
    "    scores = {\n",
    "        'Classifier': mlp,\n",
    "        'Feature_extraction': embed_model,\n",
    "        'Weighting': ros,\n",
    "        'CV': kfold,\n",
    "        'Text_length': text_length,\n",
    "        'F1_tr_cv': round(f1_score(y_train, y_train_pred_cv), 3),\n",
    "        'F1_tr': round(f1_score(y_train, y_train_pred), 3),\n",
    "        'F1_ts': round(f1_score(y_test, y_test_pred), 3),\n",
    "        'Precision_tr_cv': round(precision_score(y_train, y_train_pred_cv), 3),\n",
    "        'Precision_tr': round(precision_score(y_train, y_train_pred), 3),\n",
    "        'Precision_ts': round(precision_score(y_test, y_test_pred), 3),\n",
    "        'Recall_tr_cv': round(recall_score(y_train, y_train_pred_cv), 3),\n",
    "        'Recall_tr': round(recall_score(y_train, y_train_pred), 3),\n",
    "        'Recall_ts': round(recall_score(y_test, y_test_pred), 3)    \n",
    "    }\n",
    "\n",
    "    all_scores.append(scores)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train eval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF baseline and weighted\n",
    "\n",
    "df1 = pd.DataFrame(train_eval_tf_tfidf(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df2 = pd.DataFrame(train_eval_tf_tfidf(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings baseline and weighted\n",
    "\n",
    "df3 = pd.DataFrame(train_eval_embeddings(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2))\n",
    "df4 = pd.DataFrame(train_eval_embeddings(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF TFIDF resampled\n",
    "\n",
    "df5 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train, y_train, x_test, y_test,'Title_Abstract',2))\n",
    "df6 = pd.DataFrame(train_eval_tf_tfidf_resampled(x_train_long, y_train_long, x_test_long, y_test_long,'Title_Abstract_Main',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings resampled\n",
    "\n",
    "df7 = pd.DataFrame(train_eval_embedding_resampled(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2, model_mpnet))\n",
    "df8 = pd.DataFrame(train_eval_embedding_resampled(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2, model_mpnet))\n",
    "\n",
    "df9 = pd.DataFrame(train_eval_embedding_resampled(x_train_r, y_train_r, x_test_r, y_test_r,'Title_Abstract',2, model_distill))\n",
    "df10 = pd.DataFrame(train_eval_embedding_resampled(x_train_r_long, y_train_r_long, x_test_r_long, y_test_r_long,'Title_Abstract_Main',2, model_distill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cocatenate and save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "res = res.sort_values(by=['Recall_ts','F1_tr_cv'], ascending=[False, False]).reset_index(drop=True)\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model scores\n",
    "\n",
    "res.to_csv('../results/model_scores/model_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
