{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e74ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# February 2024\n",
    "# Text classifier using logistic regression, support vector machine, and xlm-roberta\n",
    "# Violeta Berdejo-Espinola and √Åkos Hajas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8000d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d1fc0",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c898e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "\n",
    "X_train_cv = mpu.io.read('../data/X_train_cv.pickle')\n",
    "X_test_cv = mpu.io.read('../data/X_test_cv.pickle')\n",
    "X_train_tfidf = mpu.io.read('../data/X_train_tfidf.pickle')\n",
    "X_test_tfidf = mpu.io.read('../data/X_test_tfidf.pickle')\n",
    "embedding_train = mpu.io.read('../data/embedding_train.pickle')\n",
    "embedding_test = mpu.io.read('../data/embedding_test.pickle')\n",
    "y_train = mpu.io.read('../data/y_train.pickle')\n",
    "y_test = mpu.io.read('../data/y_test.pickle')\n",
    "\n",
    "# resampled\n",
    "\n",
    "X_rus_train_tfidf = mpu.io.read('../data/X_rus_train_tfidf.pickle')\n",
    "y_rus_train_tfidf = mpu.io.read('../data/y_rus_train_tfidf.pickle')\n",
    "\n",
    "X_ros_train_tfidf = mpu.io.read('../data/X_ros_train_tfidf.pickle')\n",
    "y_ros_train_tfidf = mpu.io.read('../data/y_ros_train_tfidf.pickle')\n",
    "\n",
    "X_ada_train_tfidf = mpu.io.read('../data/X_ada_train_tfidf.pickle')\n",
    "y_ada_train_tfidf = mpu.io.read('../data/y_ada_train_tfidf.pickle')\n",
    "\n",
    "X_rus_train_cv = mpu.io.read('../data/X_rus_train_cv.pickle')\n",
    "y_rus_train_cv = mpu.io.read('../data/y_rus_train_cv.pickle')\n",
    "\n",
    "X_ros_train_cv = mpu.io.read('../data/X_ros_train_cv.pickle')\n",
    "y_ros_train_cv = mpu.io.read('../data/y_ros_train_cv.pickle')\n",
    "\n",
    "X_ada_train_cv = mpu.io.read('../data/X_ada_train_cv.pickle')\n",
    "y_ada_train_cv = mpu.io.read('../data/y_ada_train_cv.pickle')\n",
    "\n",
    "X_embedding_train_ros = mpu.io.read('../data/x_emb_train_ros.pickle')\n",
    "y_embedding_train_ros = mpu.io.read('../data/y_emb_train_ros.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for x in y_test:\n",
    "    counter[x] +=1\n",
    "    \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ce5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_embedding_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0131af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = mpu.io.read('../data/pos.pickle')\n",
    "neg = mpu.io.read('../data/neg_complete.pickle')\n",
    "\n",
    "x = pos + neg\n",
    "y = [1] * len(pos) + [0] * len(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11976724",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8425e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# weights for class penalty (weighted cross-entropy loss)\n",
    "\n",
    "# weight_for_class_i = total_samples / (num_samples_in_class_i * num_classes)\n",
    "\n",
    "weight_for_class_0 = len(x) / (len(neg) * 2) \n",
    "weight_for_class_1 = len(x) / (len(pos) * 2) \n",
    "\n",
    "print(weight_for_class_0, weight_for_class_1)\n",
    "\n",
    "# instantiate models\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "svm = SVC(kernel='linear')\n",
    "logreg_weight = LogisticRegression(solver='liblinear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, random_state=42)\n",
    "svm_weight = SVC(kernel='linear', class_weight={0: weight_for_class_0, 1: weight_for_class_1}, probability=True)\n",
    "mlp = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(), learning_rate='constant',\n",
    "                    learning_rate_init=0.001, solver='adam', random_state=42)\n",
    "mlp_tuned = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(800), learning_rate='invscaling',\n",
    "                    learning_rate_init=0.001, solver='sgd', random_state=42)\n",
    "\n",
    "# create cases\n",
    "\n",
    "Case = namedtuple(\"Case\", \"name model X Y x y vector weighting\")\n",
    "\n",
    "cases_baseline = [\n",
    "    Case(name='LR', model=logreg, X=X_train_cv, Y=y_train, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='None'),\n",
    "    \n",
    "    Case(name='SVM', model=svm, X=X_train_cv, Y=y_train, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='None'),\n",
    "    \n",
    "    Case(name='LR', model=logreg, X=X_train_tfidf, Y=y_train, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='None'),\n",
    "    \n",
    "    Case(name='SVM', model=svm, X=X_train_tfidf, Y=y_train, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='None'),\n",
    "    \n",
    "    Case(name='LR', model=logreg, X=embedding_train, Y=y_train, x=embedding_test, y=y_test, vector=\"embedding\", weighting='None'),\n",
    "    \n",
    "    Case(name='SVM', model=svm, X=embedding_train, Y=y_train, x=embedding_test, y=y_test, vector=\"embedding\", weighting='None'),\n",
    "    \n",
    "    Case(name='MLP', model=mlp, X=embedding_train, Y=y_train, x=embedding_test, y=y_test, vector=\"embedding\", weighting='None')\n",
    "]\n",
    "\n",
    "cases_weighted = [\n",
    "    Case(name='LR', model=logreg_weight, X=X_train_cv, Y=y_train, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='BAL'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=svm_weight, X=X_train_cv, Y=y_train, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='BAL'),\n",
    "    \n",
    "    Case(name='LR', model=logreg_weight, X=X_train_tfidf, Y=y_train, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='BAL'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=svm_weight, X=X_train_tfidf, Y=y_train, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='BAL'),\n",
    "    \n",
    "    Case(name='LR', model=logreg_weight, X=embedding_train, Y=y_train, x=embedding_test, y=y_test, vector=\"embedding\", weighting=\"BAL\"),\n",
    "    \n",
    "    Case(name='SVM', model=svm_weight, X=embedding_train, Y=y_train, x=embedding_test, y=y_test, vector=\"embedding\", weighting=\"BAL\")\n",
    "]\n",
    "\n",
    "cases_resampled_tfidf = [\n",
    "    Case(name=\"LR\", model=logreg, X=X_rus_train_tfidf, Y=y_rus_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='RUS'),\n",
    "     \n",
    "    Case(name=\"LR\", model=svm, X=X_ros_train_tfidf, Y=y_ros_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='ROS'),\n",
    "    \n",
    "    Case(name=\"LR\", model=svm, X=X_ada_train_tfidf, Y=y_ada_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='ADA'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=svm, X=X_rus_train_tfidf, Y=y_rus_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='RUS'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=svm, X=X_ros_train_tfidf, Y=y_ros_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='ROS'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=svm, X=X_ada_train_tfidf, Y=y_ada_train_tfidf, x=X_test_tfidf, y=y_test, vector=\"TF-IDF\", weighting='ADA')\n",
    "]\n",
    "\n",
    "cases_resampled_cv = [\n",
    "    Case(name=\"LR\", model=logreg, X=X_rus_train_cv, Y=y_rus_train_cv, x=X_test_cv, y=y_test,  vector=\"word_frequency\", weighting='RUS'),\n",
    "    \n",
    "    Case(name=\"LR\", model=logreg, X=X_ros_train_cv, Y=y_ros_train_cv, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='ROS'),\n",
    "    \n",
    "    Case(name=\"LR\", model=logreg, X=X_ada_train_cv, Y=y_ada_train_cv, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='ADA'),\n",
    "    \n",
    "    Case(name=\"SVM\", model=logreg, X=X_rus_train_cv, Y=y_rus_train_cv, x=X_test_cv, y=y_test,  vector=\"word_frequency\", weighting='RUS'),   \n",
    "    \n",
    "    Case(name=\"SVM\", model=logreg, X=X_ros_train_cv, Y=y_ros_train_cv, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='ROS'),\n",
    "        \n",
    "    Case(name=\"SVM\", model=logreg, X=X_ada_train_cv, Y=y_ada_train_cv, x=X_test_cv, y=y_test, vector=\"word_frequency\", weighting='ADA')\n",
    "]\n",
    "\n",
    "cases_resampled_embedding = [\n",
    "    Case(name='LR', model=logreg, X=X_embedding_train_ros, Y=y_embedding_train_ros, x=embedding_test, y=y_test, vector='embbeding', weighting='ROS'),\n",
    "    \n",
    "    Case(name='MLP', model=mlp, X=X_embedding_train_ros, Y=y_embedding_train_ros, x=embedding_test, y=y_test, vector='embbeding', weighting='ROS'),\n",
    "    \n",
    "    Case(name='MLP-TUNED', model=mlp_tuned, X=X_embedding_train_ros, Y=y_embedding_train_ros, x=embedding_test, y=y_test, vector='embbeding', weighting='ROS')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff91ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fit models, make predictions with train and test sets\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "def get_scores(cases):\n",
    "    # create lists to store information of each model and their prediction scores for train and test set\n",
    "    scores_list = []\n",
    "    models_list = []\n",
    "\n",
    "    for case in cases:\n",
    "        \n",
    "        # fit models and make predictions\n",
    "        model = case.model.fit(case.X, case.Y)\n",
    "        \n",
    "        if case.name in ['LR','SVM']:\n",
    "            \n",
    "            y_train_pred = cross_val_predict(case.model, case.X, case.Y, cv=StratifiedKFold(10), method='predict')\n",
    "            y_test_pred = model.predict(case.x)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            y_test_pred = model.predict(case.x)\n",
    "            \n",
    "\n",
    "        # save fitted model\n",
    "        models = {\n",
    "            \"name\": f'{case.name}_{case.weighting}_{case.vector}',\n",
    "            \"model\": model,\n",
    "            \n",
    "        }\n",
    "        \n",
    "        # save scores from predicitons\n",
    "        scores = {\n",
    "            'Classifier': case.name,\n",
    "            'Numeric_rep': case.vector,\n",
    "            'Weighting': case.weighting,\n",
    "            'Instances': len(case.Y),\n",
    "            'F1_tr': round(f1_score(case.Y, y_train_pred), 3),\n",
    "            'F1_ts': round(f1_score(case.y, y_test_pred), 3),\n",
    "            'Precision_tr': round(precision_score(case.Y, y_train_pred), 3),\n",
    "            'Precision_ts': round(precision_score(case.y, y_test_pred), 3),\n",
    "            'Recall_tr': round(recall_score(case.Y, y_train_pred), 3),\n",
    "            'Recall_ts': round(recall_score(case.y, y_test_pred), 3)\n",
    "        }\n",
    "        \n",
    "        # store each model's dict and prediciton scores' dict in a list\n",
    "        models_list.append(models)\n",
    "        scores_list.append(scores)\n",
    "        \n",
    "    return models_list, scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1decaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fit models and make predictions\n",
    "\n",
    "models_baseline, scores_baseline = get_scores(cases_baseline)\n",
    "models_weighted, scores_weighted = get_scores(cases_weighted)\n",
    "models_resampled_tfidf, scores_resampled_tfidf = get_scores(cases_resampled_tfidf)\n",
    "models_resampled_cv, scores_resampled_cv = get_scores(cases_resampled_cv)\n",
    "models_resampled_embedding, scores_resampled_embedding = get_scores(cases_resampled_embedding)\n",
    "\n",
    "df1 = pd.DataFrame(scores_baseline)\n",
    "df2 = pd.DataFrame(scores_weighted)\n",
    "df3 = pd.DataFrame(scores_resampled_tfidf)\n",
    "df4 = pd.DataFrame(scores_resampled_cv)\n",
    "df5 = pd.DataFrame(scores_resampled_embedding)\n",
    "\n",
    "results =  pd.concat([df1,df2,df3,df4,df5])\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d60627",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results.sort_values(by='Recall_ts', ascending=False).reset_index(drop=True)\n",
    "# res.to_csv('../results/logreg_svm_mlp_results.csv')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e70179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best tuning MLP\n",
    "\n",
    "# batch_size=32 is not too bad either\n",
    "\n",
    "mlp_tuned = MLPClassifier(activation='logistic', batch_size=16, hidden_layer_sizes=(800), learning_rate='invscaling',\n",
    "                    learning_rate_init=0.001, solver='sgd', random_state=42).fit(X_embedding_train_ros, y_embedding_train_ros)\n",
    "\n",
    "y_pred = mlp_tuned.predict(embedding_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adb360",
   "metadata": {},
   "source": [
    "# calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78feb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loglikelihood\n",
    "\n",
    "# log_likelihood = y_test*np.log(y_pred) + (1-y_test)*np.log(1-y_pred)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_loglikelihood(estimator):\n",
    "    model = estimator.fit(embedding_train, y_train)\n",
    "    y_pred = model.predict_proba(embedding_test)\n",
    "    logloss = log_loss(y_test, y_pred)\n",
    "    \n",
    "    return logloss\n",
    "\n",
    "def calculate_loglikelihood_ovrsmpld(estimator):\n",
    "    model = estimator.fit(X_embedding_train_ros, y_embedding_train_ros)\n",
    "    y_pred = model.predict_proba(embedding_test)\n",
    "    logloss = log_loss(y_test, y_pred)\n",
    "    \n",
    "    return logloss\n",
    "loss_logreg_ovrsmpld = calculate_loglikelihood(logreg)\n",
    "# loss_mlp_ovrsampld = loglikelihood_loss(mlp_tuned, X_embedding_train_ros, y_embedding_train_ros, embedding_test, y_test)\n",
    "\n",
    "print(loss_logreg_ovrsmpld)#, loss_mlp_ovrsampld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd45981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model loss - MLP TUNED\n",
    "\n",
    "loss_values = mlp_tuned.loss_curve_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('MLP-TUNED model loss')\n",
    "\n",
    "plt.savefig('../results/mlp-tuned_loss.png', dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1231b",
   "metadata": {},
   "source": [
    "# best-performing models\n",
    "# roc auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62839d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict probabilities, compute auc score and roc curve \n",
    "\n",
    "def get_auc_roc(estimator, x_train, y_train, x_test, y_test):\n",
    "    best_model = estimator.fit(x_train, y_train)\n",
    "    pred_prob = best_model.predict_proba(x_test)\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    auc_score = roc_auc_score(y_test, pred_prob[:,1])\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
    "    \n",
    "    return auc_score, fpr, tpr, y_pred\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_lr_weight, fpr_lr_weight, tpr_lr_weight, y_pred_lr_weight= get_auc_roc(logreg_weight, embedding_train, y_train, embedding_test, y_test)\n",
    "\n",
    "auc_lr_ovsmpld, fpr_lr_ovsmpld, tpr_lr_ovsmpld, y_pred_lr_ovsmpld = get_auc_roc(logreg, X_embedding_train_ros, y_embedding_train_ros, embedding_test, y_test)\n",
    "\n",
    "auc_svm_weight, fpr_svm_weight, tpr_svm_weight, y_pred_svm_weight = get_auc_roc(svm_weight, embedding_train, y_train, embedding_test, y_test)\n",
    "\n",
    "auc_mlp_ovsmpld, fpr_mlp_ovsmpld, tpr_mlp_ovsmpld, y_pred_mlp_ovsmpld = get_auc_roc(mlp_tuned, X_embedding_train_ros, y_embedding_train_ros, embedding_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lr_weight,auc_lr_ovsmpld,auc_svm_weight,auc_mlp_ovsmpld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr_lr_weight, tpr_lr_weight, linestyle='--',color='#bbca', label='SVM - weighted')\n",
    "plt.plot(fpr_svm_weight, tpr_svm_weight, linestyle='--',color='orange', label='Logistic Regression - weighted')\n",
    "plt.plot(fpr_lr_ovsmpld, tpr_lr_ovsmpld, linestyle='--',color='green', label='Logistic Regression - oversampled')\n",
    "plt.plot(fpr_mlp_ovsmpld, tpr_mlp_ovsmpld, linestyle='--',color='gray', label='MLP Logistic Regression - oversampled')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "# plt.savefig('ROC',dpi=800)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_confusion_matrix(y_test, y_pred):\n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return cm\n",
    "\n",
    "cm1 = create_confusion_matrix(y_test, y_pred_lr_weight)\n",
    "cm2 = create_confusion_matrix(y_test, y_pred_svm_weight)\n",
    "cm3 = create_confusion_matrix(y_test, y_pred_lr_ovr)\n",
    "cm4 = create_confusion_matrix(y_test, y_pred_lr_weight)\n",
    "\n",
    "cm = pd.concat([cm1,cm2,cm3,cm4])\n",
    "\n",
    "# cm = pd.DataFrame({'logreg-weighted': cm1, \n",
    "#                    'svm-weighted': cm2, \n",
    "#                    'logreg-ovrsmpld': cm4,\n",
    "#                    'mlp_logreg-ovrsmpld': cm3 \n",
    "#                   })\n",
    "\n",
    "# cm.to_csv('../results/logreg_svm_mlp_confusion_matrix.csv')\n",
    "cm\n",
    "\n",
    "#true negatives, false positives\n",
    "#false negatives, true positives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
