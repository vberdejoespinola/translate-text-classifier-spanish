{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ae16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# September 2023\n",
    "# Data exploration and cleaning\n",
    "# Violeta Berdejo-Espinola & Ákos Hájas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linting \n",
    "# !nbqa pylint 1.pre_process_main_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d51552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from Levenshtein import ratio # string similarity metric that measures the difference between two sequences\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 150)\n",
    "\n",
    "df_repo = pd.read_csv(\n",
    "    \"../datasets/from_repo/majom_september_pos_added.csv\",\n",
    "    header=None,\n",
    "    index_col=0,\n",
    "    names=[\n",
    "        \"id\",\n",
    "        \"title_spa\",\n",
    "        \"journal_name\",\n",
    "        \"pub_year\",\n",
    "        \"country\",\n",
    "        \"abstract_eng\",\n",
    "        \"main_text_eng\",\n",
    "        \"ci_eng\",\n",
    "        \"abstract_spa\",\n",
    "        \"main_text_spa\",\n",
    "        \"ci_spa\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_pos = pd.read_csv(\n",
    "    \"../datasets/from_translate/translatE_spanish_positives_71.csv\", \n",
    "    encoding=\"utf-8\",\n",
    "    names=[\n",
    "        \"title_spa\",\n",
    "        'Publication_type',\n",
    "        \"journal_name\",\n",
    "        \"abstract_spa\",\n",
    "        \"label\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "df_pos = df_pos.drop([\"Publication_type\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30977708",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616921a",
   "metadata": {},
   "source": [
    "# Clean dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcc5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_title = df_repo[\"title_spa\"].str.contains(\"In Memoriam|Editorial|Fe de erratas|FE DE ERRATA|ERRATA|aniversario|ARTÍCULO RETRACTADO\")\n",
    "bad_body = df_repo[\"main_text_spa\"].str.contains(\"Texto completo disponible sólo en PDF|Full text available only in PDF format Texto completo disponible sólo en PDF\")\n",
    "             \n",
    "df_repo = df_repo.dropna(subset=[\"title_spa\", \"abstract_spa\", \"main_text_spa\", \"journal_name\"])\n",
    "df_repo = df_repo[~bad_title | ~bad_body]\n",
    "\n",
    "df_repo.title_spa.duplicated().sum()\n",
    "# df_repo.index.has_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize titles and journal name from df_repo and df_pos\n",
    "\n",
    "def normalize_title(title):\n",
    "    title = re.sub(\"\\s+\", \" \", title).capitalize().strip().replace(\".\", \"\")\n",
    "    title = re.sub(\"\\xa0\", \" \", title)\n",
    "    return re.sub(\"\\n{1,}\", \" \", title)\n",
    "\n",
    "df_pos[\"title_spa\"] = df_pos[\"title_spa\"].apply(normalize_title)\n",
    "df_repo[\"title_spa\"] = df_repo[\"title_spa\"].apply(normalize_title)\n",
    "df_repo[\"journal_name\"] = df_repo[\"journal_name\"].apply(lambda name: name.capitalize().strip())\n",
    "\n",
    "repo_titles = df_repo[\"title_spa\"] #5019\n",
    "pos_titles = df_pos[\"title_spa\"] #69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d653e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(repo_titles)\n",
    "len(df_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda48c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find similarity between titles from df_repo and df_pos\n",
    "\n",
    "# each item in ratios is one title from repo mapped to similarity of all titles from the positives: 1 title -> 69 titles x 5000 titles\n",
    "ratios = repo_titles.map(lambda title_repo: pos_titles.map(lambda title_pos: ratio(title_pos, title_repo)))\n",
    "\n",
    "# for the 5019 sets of 69 ratios, map the 69 numbers to a boolean by checking if it's high enough\n",
    "similarity = ratios.map(lambda ratio: ratio > 0.82)\n",
    "\n",
    "# reduce the 69 boolean to one by checking if _any_ of them is true -> a match between repo title and pos title\n",
    "matches = similarity.map(lambda ratios: ratios.any()) #if any is TRUE\n",
    "\n",
    "print(len(matches)) # 5019\n",
    "print(len(df_repo)) # 5019\n",
    "\n",
    "# df_match = df_repo[\n",
    "#     df_repo[\"title_spa\"].map(lambda title_repo: df_pos[\"title_spa\"].map(lambda title: ratio(title, title_repo)).map(lambda ratio: ratio > 0.92).any())\n",
    "# ][\"title_spa\"]\n",
    "\n",
    "# ratios[\"S2007-11322019000600238\"]\n",
    "# similarity[\"S2007-11322019000600238\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ratios)\n",
    "ratios[1:2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titles in pos that are not in matches\n",
    "\n",
    "pos_matches = similarity[0]\n",
    "for row in similarity[1:]:\n",
    "    pos_matches += row\n",
    "\n",
    "print(len(df_pos[~pos_matches]))\n",
    "df_pos[~pos_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dfs, drop duplicates, label pos and neg\n",
    "\n",
    "df_match = df_repo[matches][[\"title_spa\",\"abstract_spa\",\"main_text_spa\",\"journal_name\"]]\n",
    "df_match['label'] = \"positive\"\n",
    "df_repo = df_repo[[\"title_spa\",\"abstract_spa\",\"main_text_spa\",\"journal_name\"]]\n",
    "df_repo['label'] = \"\"\n",
    "df_combined = pd.concat([df_match, df_repo])\n",
    "df_combined = df_combined.drop_duplicates(subset=[\"title_spa\"], keep=\"first\")\n",
    "df_combined['label'] = df_combined.label.replace('','negative',regex = True)\n",
    "\n",
    "print(len(df_combined[df_combined['label'] == \"positive\"]))\n",
    "print(len(df_combined[df_combined['label'] == \"negative\"]))\n",
    "print(len(df_combined))\n",
    "df_combined.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a44534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('C:\\\\Users\\\\uqvberde\\\\Dropbox\\\\TRANSLATE\\\\ML\\\\classifier_spanish\\\\datasets\\\\py_outputs\\\\pos_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample negatives and create final dfs\n",
    "\n",
    "df_neg = df_combined.loc[df_combined.label == \"negative\"]\n",
    "\n",
    "def sample_negs(neg):\n",
    "    sampled = neg.sample(n = len(df_match))\n",
    "    return sampled\n",
    "\n",
    "def final_df(pos, neg):\n",
    "    df = pd.concat([pos, sample_negs(neg)])\n",
    "    return df\n",
    "\n",
    "def generate_sample_sets(count):\n",
    "    return list(map(lambda _: final_df(df_match, df_neg), range(count)))\n",
    "\n",
    "sample_sets = generate_sample_sets(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe296ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(sample_sets):\n",
    "    sample.to_csv('C:\\\\Users\\\\uqvberde\\\\Dropbox\\\\TRANSLATE\\\\ML\\\\classifier_spanish\\\\datasets\\\\py_outputs\\\\data\\\\71\\\\pos_neg_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84399265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, sample in enumerate(sample_sets):\n",
    "#     sample.to_csv(f'/Users/uqvberde/Dropbox/TRANSLATE/Objective 2 - Machine Learning/classifier_spanish/datasets/py_outputs/pos_neg/pos_neg_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eddd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_sets)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
